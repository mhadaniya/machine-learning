{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 14: Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5: Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree has accuracy:  0.668161434978\n",
      "GaussianNB has accuracy:  0.681614349776\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# In this and the following exercises, you'll be adding train test splits to the data\n",
    "# to see how it changes the performance of each classifier\n",
    "#\n",
    "# The code provided will load the Titanic dataset like you did in project 0, then train\n",
    "# a decision tree (the method you used in your project) and a Bayesian classifier (as\n",
    "# discussed in the introduction videos). You don't need to worry about how these work for\n",
    "# now. \n",
    "#\n",
    "# What you do need to do is import a train/test split, train the classifiers on the\n",
    "# training data, and store the resulting accuracy scores in the dictionary provided.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "X = pd.read_csv('datasets/titanic_data.csv')\n",
    "# Limit to numeric data\n",
    "X = X._get_numeric_data()\n",
    "# Separate the labels\n",
    "y = X['Survived']\n",
    "# Remove labels from the inputs, and age due to missing data\n",
    "del X['Age'], X['Survived']\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO: split the data into training and testing sets,\n",
    "# using the standard settings for train_test_split.\n",
    "# Then, train and test the classifiers with your newly split data instead of X and y.\n",
    "\n",
    "train, test, train_lb, test_lb = train_test_split(X, y)\n",
    "\n",
    "# The decision tree classifier\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf1.fit(train, train_lb)\n",
    "print(\"Decision Tree has accuracy: \", str(accuracy_score(test_lb , clf1.predict(test))))\n",
    "# The naive Bayes classifier\n",
    "\n",
    "clf2 = GaussianNB()\n",
    "clf2.fit(train, train_lb)\n",
    "print(\"GaussianNB has accuracy: \", str(accuracy_score(test_lb, clf2.predict(test))))\n",
    "\n",
    "answer = { \n",
    " \"Naive Bayes Score\": 0, \n",
    " \"Decision Tree Score\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 15. Build a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous-multioutput'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bd1c1d210d94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mclf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mclf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Confusion matrix for this Decision Tree:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mhadaniya/anaconda2/envs/py27/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    740\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mhadaniya/anaconda2/envs/py27/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_classification\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mhadaniya/anaconda2/envs/py27/lib/python2.7/site-packages/sklearn/utils/multiclass.pyc\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    170\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    171\u001b[0m             'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous-multioutput'"
     ]
    }
   ],
   "source": [
    "# In this exercise, we'll use the Titanic dataset as before, train two classifiers and\n",
    "# look at their confusion matrices. Your job is to create a train/test split in the data\n",
    "# and report the results in the dictionary at the bottom.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "from sklearn import datasets\n",
    "\n",
    "X = pd.read_csv('datasets/titanic_data.csv')\n",
    "\n",
    "X = X._get_numeric_data()\n",
    "y = X['Survived']\n",
    "del X['Age'], X['Survived']\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# TODO: split the data into training and testing sets,\n",
    "# using the default settings for train_test_split (or test_size = 0.25 if specified).\n",
    "# Then, train and test the classifiers with your newly split data instead of X and y.\n",
    "\n",
    "x_train, y_train, x_test, y_test = cross_validation.train_test_split(X, y)\n",
    "\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf1.fit(x_train, y_train)\n",
    "print \"Confusion matrix for this Decision Tree:\\n\",confusion_matrix(y_test, clf1.predict(x_test))\n",
    "\n",
    "clf2 = GaussianNB()\n",
    "clf2.fit(x_train, y_train)\n",
    "print \"GaussianNB confusion matrix:\\n\",confusion_matrix(y_test,clf2.predict(x_test))\n",
    "\n",
    "#TODO: store the confusion matrices on the test sets below\n",
    "\n",
    "confusions = {\n",
    " \"Naive Bayes\": confusion_matrix(y_test, clf1.predict(x_test)),\n",
    " \"Decision Tree\": confusion_matrix(y_test,clf2.predict(x_test))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7",
   "language": "python",
   "name": "py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
