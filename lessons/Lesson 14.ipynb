{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 14: Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5: Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Decision Tree has accuracy: ', '0.650224215247')\n",
      "('GaussianNB has accuracy: ', '0.659192825112')\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# In this and the following exercises, you'll be adding train test splits to the data\n",
    "# to see how it changes the performance of each classifier\n",
    "#\n",
    "# The code provided will load the Titanic dataset like you did in project 0, then train\n",
    "# a decision tree (the method you used in your project) and a Bayesian classifier (as\n",
    "# discussed in the introduction videos). You don't need to worry about how these work for\n",
    "# now. \n",
    "#\n",
    "# What you do need to do is import a train/test split, train the classifiers on the\n",
    "# training data, and store the resulting accuracy scores in the dictionary provided.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "X = pd.read_csv('datasets/titanic_data.csv')\n",
    "# Limit to numeric data\n",
    "X = X._get_numeric_data()\n",
    "# Separate the labels\n",
    "y = X['Survived']\n",
    "# Remove labels from the inputs, and age due to missing data\n",
    "del X['Age'], X['Survived']\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO: split the data into training and testing sets,\n",
    "# using the standard settings for train_test_split.\n",
    "# Then, train and test the classifiers with your newly split data instead of X and y.\n",
    "\n",
    "train, test, train_lb, test_lb = train_test_split(X, y)\n",
    "\n",
    "# The decision tree classifier\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf1.fit(train, train_lb)\n",
    "print(\"Decision Tree has accuracy: \", str(accuracy_score(test_lb , clf1.predict(test))))\n",
    "# The naive Bayes classifier\n",
    "\n",
    "clf2 = GaussianNB()\n",
    "clf2.fit(train, train_lb)\n",
    "print(\"GaussianNB has accuracy: \", str(accuracy_score(test_lb, clf2.predict(test))))\n",
    "\n",
    "answer = { \n",
    " \"Naive Bayes Score\": 0, \n",
    " \"Decision Tree Score\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 15. Build a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for this Decision Tree:\n",
      "[[97 41]\n",
      " [39 46]]\n",
      "GaussianNB confusion matrix:\n",
      "[[121  17]\n",
      " [ 49  36]]\n"
     ]
    }
   ],
   "source": [
    "# In this exercise, we'll use the Titanic dataset as before, train two classifiers and\n",
    "# look at their confusion matrices. Your job is to create a train/test split in the data\n",
    "# and report the results in the dictionary at the bottom.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "from sklearn import datasets\n",
    "\n",
    "X = pd.read_csv('datasets/titanic_data.csv')\n",
    "\n",
    "X = X._get_numeric_data()\n",
    "y = X['Survived']\n",
    "del X['Age'], X['Survived']\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# TODO: split the data into training and testing sets,\n",
    "# using the default settings for train_test_split (or test_size = 0.25 if specified).\n",
    "# Then, train and test the classifiers with your newly split data instead of X and y.\n",
    "train, test, train_lb, test_lb = cross_validation.train_test_split(X, y)\n",
    "\n",
    "\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf1.fit(train, train_lb)\n",
    "print \"Confusion matrix for this Decision Tree:\\n\",confusion_matrix(test_lb,clf1.predict(test))\n",
    "\n",
    "clf2 = GaussianNB()\n",
    "clf2.fit(train, train_lb)\n",
    "print \"GaussianNB confusion matrix:\\n\",confusion_matrix(test_lb,clf2.predict(test))\n",
    "\n",
    "#TODO: store the confusion matrices on the test sets below\n",
    "\n",
    "confusions = {\n",
    " \"Naive Bayes\": confusion_matrix(test_lb,clf1.predict(test)),\n",
    " \"Decision Tree\": confusion_matrix(test_lb,clf2.predict(test))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 26. Precision vs. Recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree recall: 0.54 and precision: 0.55\n",
      "GaussianNB recall: 0.40 and precision: 0.67\n"
     ]
    }
   ],
   "source": [
    "# As with the previous exercises, let's look at the performance of a couple of classifiers\n",
    "# on the familiar Titanic dataset. Add a train/test split, then store the results in the\n",
    "# dictionary provided.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "X = pd.read_csv('datasets/titanic_data.csv')\n",
    "\n",
    "X = X._get_numeric_data()\n",
    "y = X['Survived']\n",
    "del X['Age'], X['Survived']\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn.metrics import precision_score as precision\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import cross_validation\n",
    "\n",
    "\n",
    "# TODO: split the data into training and testing sets,\n",
    "# using the standard settings for train_test_split.\n",
    "# Then, train and test the classifiers with your newly split data instead of X and y.\n",
    "train, test, train_lb, test_lb = cross_validation.train_test_split(X, y)\n",
    "\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf1.fit(train, train_lb)\n",
    "print \"Decision Tree recall: {:.2f} and precision: {:.2f}\".format(recall(test_lb,clf1.predict(test)),precision(test_lb,clf1.predict(test)))\n",
    "\n",
    "clf2 = GaussianNB()\n",
    "clf2.fit(train, train_lb)\n",
    "print \"GaussianNB recall: {:.2f} and precision: {:.2f}\".format(recall(test_lb,clf2.predict(test)),precision(test_lb,clf2.predict(test)))\n",
    "\n",
    "results = {\n",
    "  \"Naive Bayes Recall\": recall(test_lb,clf2.predict(test)),\n",
    "  \"Naive Bayes Precision\": precision(test_lb,clf2.predict(test)),\n",
    "  \"Decision Tree Recall\": recall(test_lb,clf1.predict(test)),\n",
    "  \"Decision Tree Precision\": precision(test_lb,clf1.predict(test))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 29. Compute F1 Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree F1 score: 0.49\n",
      "GaussianNB F1 score: 0.47\n"
     ]
    }
   ],
   "source": [
    "# As usual, use a train/test split to get a reliable F1 score from two classifiers, and\n",
    "# save it the scores in the provided dictionaries.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "X = pd.read_csv('datasets/titanic_data.csv')\n",
    "\n",
    "X = X._get_numeric_data()\n",
    "y = X['Survived']\n",
    "del X['Age'], X['Survived']\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# TODO: split the data into training and testing sets,\n",
    "# using the standard settings for train_test_split.\n",
    "# Then, train and test the classifiers with your newly split data instead of X and y.\n",
    "\n",
    "x_train, x_test, y_train, y_test = cross_validation.train_test_split(X,y) \n",
    "\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf1.fit(x_train, y_train)\n",
    "print \"Decision Tree F1 score: {:.2f}\".format(f1_score(y_test, clf1.predict(x_test)))\n",
    "\n",
    "clf2 = GaussianNB()\n",
    "clf2.fit(x_train, y_train)\n",
    "print \"GaussianNB F1 score: {:.2f}\".format(f1_score(y_test, clf2.predict(x_test)))\n",
    "\n",
    "F1_scores = {\n",
    " \"Naive Bayes\": f1_score(y_test, clf1.predict(x_test)),\n",
    " \"Decision Tree\": f1_score(y_test, clf2.predict(x_test))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 32. Compute Mean Absolute Error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree mean absolute error: 7.87\n",
      "Linear regression mean absolute error: 10.78\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "from sklearn.datasets import load_linnerud\n",
    "\n",
    "linnerud_data = load_linnerud()\n",
    "X = linnerud_data.data\n",
    "y = linnerud_data.target\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# TODO: split the data into training and testing sets,\n",
    "# using the standard settings for train_test_split.\n",
    "# Then, train and test the classifiers with your newly split data instead of X and y.\n",
    "x_train, x_test, y_train, y_test = cross_validation.train_test_split(X,y)\n",
    "\n",
    "reg1 = DecisionTreeRegressor()\n",
    "reg1.fit(x_train, y_train)\n",
    "print \"Decision Tree mean absolute error: {:.2f}\".format(mae(y_test,reg1.predict(x_test)))\n",
    "\n",
    "reg2 = LinearRegression()\n",
    "reg2.fit(x_train, y_train)\n",
    "print \"Linear regression mean absolute error: {:.2f}\".format(mae(y_test,reg2.predict(x_test)))\n",
    "\n",
    "results = {\n",
    " \"Linear Regression\": mae(y_test,reg2.predict(x_test)),\n",
    " \"Decision Tree\": mae(y_test,reg1.predict(x_test))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 34. Compute Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree mean absolute error: 1167.47\n",
      "Linear regression mean absolute error: 339.76\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "from sklearn.datasets import load_linnerud\n",
    "\n",
    "linnerud_data = load_linnerud()\n",
    "X = linnerud_data.data\n",
    "y = linnerud_data.target\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# TODO: split the data into training and testing sets,\n",
    "# using the standard settings for train_test_split.\n",
    "# Then, train and test the classifiers with your newly split data instead of X and y.\n",
    "x_train, x_test, y_train, y_test = cross_validation.train_test_split(X,y)\n",
    "\n",
    "reg1 = DecisionTreeRegressor()\n",
    "reg1.fit(x_train, y_train)\n",
    "print \"Decision Tree mean absolute error: {:.2f}\".format(mse(y_test, reg1.predict(x_test)))\n",
    "\n",
    "reg2 = LinearRegression()\n",
    "reg2.fit(x_train, y_train)\n",
    "print \"Linear regression mean absolute error: {:.2f}\".format(mse(y_test, reg2.predict(x_test)))\n",
    "\n",
    "results = {\n",
    " \"Linear Regression\": mse(y_test, reg2.predict(x_test)),\n",
    " \"Decision Tree\": mse(y_test, reg1.predict(x_test))\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7",
   "language": "python",
   "name": "py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
